{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqYsmiKN5kAL"
      },
      "source": [
        "***Милютина Лилия Александровна***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYvbR8PJ4tvJ"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-bgKbb44A-6"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NkbRkeKKiI_"
      },
      "source": [
        "**Считываем данные из диска**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFqTsv4OHZqh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QvH1ZNK3thM"
      },
      "source": [
        "data_path = \"/content/drive/MyDrive/ml3/\"\n",
        "train_ann_path = data_path + 'train.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_ann_path)\n",
        "print(train_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oylV7EXW6Rvp"
      },
      "source": [
        "!unzip -q '/content/drive/MyDrive/ml3/train.zip' -d './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twYGV0BJFzCs"
      },
      "source": [
        "!unzip -q '/content/drive/MyDrive/ml3/test.zip' -d './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxzdBUft97Iu"
      },
      "source": [
        "print(len(os.listdir('./train/')))\n",
        "print(len(os.listdir('./test/')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LfJMm_Xor3v"
      },
      "source": [
        "# test\n",
        "image_names = []\n",
        "for file in os.listdir('./test/'):\n",
        "  image_names.append(file)\n",
        "\n",
        "test = pd.DataFrame(image_names, columns=[\"filename\"])\n",
        "test[\"class_number\"] = 0\n",
        "test.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvUUpq5LpX5u"
      },
      "source": [
        "print(test.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68Ku0z5tKufT"
      },
      "source": [
        "**Создаем кастомный OurDataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW16NkocCAni"
      },
      "source": [
        "class OurDataset(data.Dataset):\n",
        "  \"\"\"Our dataset class.\n",
        "\n",
        "    Arguments:\n",
        "        root (str): path to images\n",
        "        imlist - pandas DataFrame with columns file_name, class\n",
        "        transform - torchvision transform applied to every image\n",
        "    \"\"\"\n",
        "  def __init__(self, root, flist, transform=None):\n",
        "        super().__init__()\n",
        "        self.root   = root\n",
        "        self.imlist = flist\n",
        "        self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        impath, target = self.imlist.loc[index] \n",
        "        \n",
        "        full_imname = os.path.join(self.root, impath)\n",
        "        \n",
        "        if not os.path.exists(full_imname):\n",
        "            print('No file ', full_imname)\n",
        "            pass\n",
        "\n",
        "        img = Image.open(full_imname).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img, target, impath\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.imlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_GsoYeTvTcQ"
      },
      "source": [
        "**Transforms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovnQXd78X6--"
      },
      "source": [
        "transform_for_train_and_val = transforms.Compose([   \n",
        "        transforms.RandomApply([\n",
        "        transforms.RandomRotation(degrees = 20),\n",
        "        transforms.RandomAffine(degrees = 0, translate=(0.1, 0.1)),\n",
        "        transforms.RandomAffine(degrees = 0, shear=20),\n",
        "        transforms.RandomAffine(degrees = 0, scale=(0.8, 0.8))]),\n",
        "        transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "transform_for_test = transforms.Compose([   \n",
        "        transforms.ToTensor()\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ouY6gzvcar"
      },
      "source": [
        "train, val = train_test_split(train_df, test_size=0.2, random_state=24)\n",
        "\n",
        "train.reset_index(inplace=True, drop=True)\n",
        "val.reset_index(inplace=True, drop=True)\n",
        "\n",
        "batch_size=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgq6nitMK6Cm"
      },
      "source": [
        "**Делаем sampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXBWC4sACQxj"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler('minority')\n",
        "X_res, y_res = ros.fit_resample(train.iloc[:, 0].to_numpy().reshape(-1, 1), train.iloc[:, 1])\n",
        "\n",
        "list_ = [X_res.tolist(), y_res.tolist()]\n",
        "train_ = pd.DataFrame(X_res, columns=[\"filename\"])\n",
        "train_[\"class_number\"] = y_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59UAv8Q856bJ"
      },
      "source": [
        "trainset = OurDataset(root='./train', flist=train_, transform=transform_for_train_and_val)\n",
        "valset = OurDataset(root='./train', flist=val, transform=transform_for_train_and_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmBFV9x_zrUg"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=8, shuffle=True, pin_memory=True)                          \n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, num_workers=8, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjzgvJyELKAl"
      },
      "source": [
        "**Посмотрим на изображения**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY7haQSQdNez"
      },
      "source": [
        "def myshow(img):\n",
        "    npimg = img.detach().numpy()\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(npimg.transpose(1, 2, 0))\n",
        "\n",
        "trainiter = iter(trainloader)\n",
        "images, labels, impaths = trainiter.next()\n",
        "myshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJgzQbkMd-3M"
      },
      "source": [
        "print(images.shape)\n",
        "print(labels)\n",
        "print(impaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OZITeO6LR6z"
      },
      "source": [
        "**Создаем модель**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0n41n-PH2Ac"
      },
      "source": [
        "nclasses = 67\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,padding=(3,3))\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5,padding=(2,2))\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3,padding=(1,1))\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(256*6*6, 256)\n",
        "        self.fc2 = nn.Linear(256, nclasses)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.batchnorm1(self.conv1(x))), 2)\n",
        "        x = F.max_pool2d(F.relu(self.batchnorm2(self.conv2(x))), 2)\n",
        "        x = F.max_pool2d(F.relu(self.batchnorm3(self.conv3(x))), 2)\n",
        "        x = x.view(-1, 256*6*6)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTAT7nZr4QaM"
      },
      "source": [
        "net = Net()\n",
        "net = net.cuda()\n",
        "\n",
        "lr = 1e-3\n",
        "num_epochs = 20\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GweoCi6gLef2"
      },
      "source": [
        "**Создаем функцию для обучения**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvxosUt_5mfK"
      },
      "source": [
        "def run_epoch(epoch, is_train):\n",
        "  \"\"\"\n",
        "  Training and evaluaton loop over samples\n",
        "  Args:\n",
        "      train_mode (bool): True for train mode\n",
        "  \"\"\"\n",
        "  if is_train:\n",
        "      net.train()\n",
        "      loader = trainloader\n",
        "      print(\"Training epoch: \", epoch + 1, \"/\", num_epochs)\n",
        "  else:\n",
        "      net.eval()\n",
        "      loader = valloader\n",
        "      print('Validation')\n",
        "      \n",
        "  running_loss = 0.0\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "\n",
        "  for i, data in enumerate(loader):\n",
        "      images, labels, _= data\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      \n",
        "      if is_train:\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      total += images.data.size(0)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += (predicted == labels.data).sum()\n",
        "      \n",
        "  print('Loss: {:.3f}, accuracy: {:.3f}'.format(running_loss / (i + 1), correct / total * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsJEfv53LmZd"
      },
      "source": [
        "**Обучение**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZVYeyj89GPD"
      },
      "source": [
        "%%time\n",
        "for epoch in range(num_epochs):\n",
        "  run_epoch(epoch, is_train=True) \n",
        "\n",
        "  with torch.no_grad():\n",
        "      run_epoch(epoch, is_train=False)\n",
        "\n",
        "  print('----------------------')\n",
        "\n",
        "print('Finished training! Enjoy your results!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDn9hbdpLuH0"
      },
      "source": [
        "**Предсказания на тестовом датасете**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXcX1TeMLoLc"
      },
      "source": [
        "testset = OurDataset(root='./test', flist=test, transform=transform_for_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=8, shuffle=False, pin_memory=True)                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtzvRiuwp59f"
      },
      "source": [
        "res = []\n",
        "for i, data in enumerate(testloader):\n",
        "    images, labels, _= data\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    outputs = net(images)\n",
        "    outputs_res = torch.argmax(outputs, dim=1).cpu().tolist()\n",
        "    res += outputs_res\n",
        "test[\"class_number\"] = res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNeFyIF324-d"
      },
      "source": [
        "test.to_csv('/content/drive/MyDrive/output.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrRCsQ_wdZTY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}